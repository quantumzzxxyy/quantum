{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 4.36 ms, total: 148 ms\n",
      "Wall time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import io\n",
    "import boto3\n",
    "import random\n",
    "\n",
    "def data_split(FILE_DATA, FILE_TRAIN, FILE_VALIDATION, FILE_TEST, Valid_Well_Name, Blind_Well_Name, TARGET_VAR):\n",
    "\n",
    "### FILE_DATA =  'facies_num.csv'\n",
    "### TARGET_VAR = 'PHIND'\n",
    "### FILE_TRAIN =  'facies_train.csv'\n",
    "### FILE_VALIDATION =  'facies_validation.csv'\n",
    "### FILE_TEST = 'facies_test.csv'\n",
    "### Valid_Well_NAME =  'SHRIMPLIN'\n",
    "### Blind_Well_Name =  'SHANKLE'    \n",
    "    \n",
    "    data = pd.read_csv(FILE_DATA)\n",
    "    n = data.shape[0]\n",
    "    ### make first col the target feature\n",
    "    cols = data.columns.tolist()\n",
    "    target_pos = data.columns.get_loc(TARGET_VAR)\n",
    "    cols.pop(target_pos)\n",
    "    cols = [TARGET_VAR] + cols\n",
    "    data = data.loc[:,cols]\n",
    "    \n",
    "    ### remove target col from test set\n",
    "    \n",
    "    ### split data into Well names\n",
    "    \n",
    "    test_data = data[data['Well Name'] == Blind_Well_Name]\n",
    "    test_data = test_data.drop(['Well Name'], axis=1)\n",
    "    \n",
    "    valid_data = data[data['Well Name'] == Valid_Well_Name]\n",
    "    valid_data = valid_data.drop(['Well Name'], axis=1)\n",
    "    \n",
    "    train_data = data[data['Well Name'] != Blind_Well_Name]\n",
    "    train_data = train_data[train_data['Well Name'] != Valid_Well_Name]\n",
    "    \n",
    "    train_data = train_data.drop(['Well Name'], axis = 1)\n",
    "    \n",
    "    train_data.to_csv(FILE_TRAIN, index=False, header=False)\n",
    "    valid_data.to_csv(FILE_VALIDATION, index=False, header=False)\n",
    "    test_data.to_csv(FILE_TEST, index=False, header=False)\n",
    "    \n",
    "def write_to_s3(fobj, bucket, key):\n",
    "        return(boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(fobj))\n",
    "\n",
    "### xgboost-dm/train/facies_train.csv\n",
    "### s3://mutest-01/xgboost-dm/train/facies_train.csv\n",
    "### Writing to {} s3://mutest-01/xgboost-dm/train/facies_train.csv    \n",
    "    \n",
    "def upload_to_s3(bucket,channel, filename):\n",
    "    fobj=open(filename, 'rb')\n",
    "    key = prefix+'/'+channel+'/'+filename\n",
    "    url = 's3://{}/{}'.format(bucket, key)\n",
    "    print(key)\n",
    "    print(url)\n",
    "    print('Writing to {}', format(url))\n",
    "    write_to_s3(fobj, bucket, key)\n",
    "    return(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### These are utilities\n",
    "#####################################################################\n",
    "### KEEP\n",
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "access_key = credentials.access_key\n",
    "secret_key = credentials.secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KEEP\n",
    "import boto3\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KEEP\n",
    "!aws s3 ls s3://'mutest-01'/xgboost-dm/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KEEP\n",
    "!aws s3 ls s3://'mutest-01'/xgboost-dm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KEEP\n",
    "#### 'mutest-01'\n",
    "import boto\n",
    "import boto.s3\n",
    "\n",
    "conn = boto.s3.connect_to_region('eu-west-1')\n",
    "bucket = conn.get_bucket('mutest-01')\n",
    "\n",
    "folders = bucket.list(\"\",\"/\")\n",
    "for folder in folders:\n",
    "    print(folder.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### KEEP\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "my_bucket = s3.Bucket('mutest-01')\n",
    "\n",
    "for file in my_bucket.objects.all():\n",
    "    print(file.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "s3.list_objects_v2(Bucket='mutest-01')\n",
    "\n",
    "##################################################### END OF UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the eu-west-1 region. You will use the 685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n",
      "CPU times: user 726 ms, sys: 80.2 ms, total: 806 ms\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "              \n",
    "from time import gmtime, strftime                 \n",
    "\n",
    "# Define IAM role\n",
    "\n",
    "# Each region has its XGBoost container\n",
    "\n",
    "role = get_execution_role()\n",
    "prefix = 'xgboost-dm'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} \n",
    "\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error:  An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n",
      "CPU times: user 73.2 ms, sys: 0 ns, total: 73.2 ms\n",
      "Wall time: 429 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bucket_name = 'mutest-01' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET :)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "      s3.create_bucket(Bucket=bucket_name)\n",
    "      print(\"create bucket\")\n",
    "    else: \n",
    "      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "      print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>0.664</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.661</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.565</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>0.658</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.050</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.5</td>\n",
       "      <td>86.10</td>\n",
       "      <td>0.655</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.115</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.647</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.300</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facies Formation  Well Name   Depth     GR  ILD_log10  DeltaPHI   PHIND  \\\n",
       "0       3     A1 SH  SHRIMPLIN  2793.0  77.45      0.664       9.9  11.915   \n",
       "1       3     A1 SH  SHRIMPLIN  2793.5  78.26      0.661      14.2  12.565   \n",
       "2       3     A1 SH  SHRIMPLIN  2794.0  79.05      0.658      14.8  13.050   \n",
       "3       3     A1 SH  SHRIMPLIN  2794.5  86.10      0.655      13.9  13.115   \n",
       "4       3     A1 SH  SHRIMPLIN  2795.0  74.58      0.647      13.5  13.300   \n",
       "\n",
       "    PE  NM_M  RELPOS  \n",
       "0  4.6     1   1.000  \n",
       "1  4.1     1   0.979  \n",
       "2  3.6     1   0.957  \n",
       "3  3.5     1   0.936  \n",
       "4  3.4     1   0.915  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 12.1 ms, total: 121 ms\n",
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### remove non numeric cols\n",
    "import pandas as pd\n",
    "\n",
    "### get from https\n",
    "### Geology example Oil & Gas\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/seg/tutorials-2016/master/1610_Facies_classification/facies_vectors.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "### put to local storage\n",
    "\n",
    "data.to_csv('facies_vectors.csv')\n",
    "\n",
    "#### remove rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "display(data.head())\n",
    "\n",
    "data['Well Name'].unique()\n",
    "\n",
    "data = data.loc[:,['Well Name', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND']]\n",
    "\n",
    "### write to disk\n",
    "data.to_csv('facies_num.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 ms, sys: 132 µs, total: 30.5 ms\n",
      "Wall time: 29.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FILE_DATA =  'facies_num.csv'\n",
    "TARGET_VAR = 'PHIND'\n",
    "FILE_TRAIN =  'facies_train.csv'\n",
    "FILE_VALIDATION =  'facies_validation.csv'\n",
    "FILE_TEST = 'facies_test.csv'\n",
    "Valid_Well_NAME =  'SHRIMPLIN'\n",
    "Blind_Well_Name =  'SHANKLE'\n",
    "\n",
    "data_split(FILE_DATA, FILE_TRAIN, FILE_VALIDATION, FILE_TEST, Valid_Well_NAME, Blind_Well_Name, TARGET_VAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost-dm/train/facies_train.csv\n",
      "s3://mutest-01/xgboost-dm/train/facies_train.csv\n",
      "Writing to {} s3://mutest-01/xgboost-dm/train/facies_train.csv\n",
      "xgboost-dm/validation/facies_validation.csv\n",
      "s3://mutest-01/xgboost-dm/validation/facies_validation.csv\n",
      "Writing to {} s3://mutest-01/xgboost-dm/validation/facies_validation.csv\n",
      "xgboost-dm/test/facies_test.csv\n",
      "s3://mutest-01/xgboost-dm/test/facies_test.csv\n",
      "Writing to {} s3://mutest-01/xgboost-dm/test/facies_test.csv\n",
      "CPU times: user 172 ms, sys: 20.9 ms, total: 193 ms\n",
      "Wall time: 353 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s3_train_loc = upload_to_s3(bucket = bucket_name, channel = 'train', filename = FILE_TRAIN)\n",
    "s3_valid_loc = upload_to_s3(bucket = bucket_name, channel = 'validation', filename = FILE_VALIDATION)\n",
    "s3_test_loc = upload_to_s3(bucket = bucket_name, channel = 'test', filename = FILE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For csv the algorithm assumes that the target variable is in teh first column and that the csv does not \n",
    "### have a header record nor lable cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instatiate the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://mutest-01/xgboost-dm/output/\n",
      "CPU times: user 43.5 ms, sys: 0 ns, total: 43.5 ms\n",
      "Wall time: 47.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "xgboost = sagemaker.estimator.Estimator(containers[my_region],\n",
    "          role,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type='ml.c4.xlarge',\n",
    "          output_path='s3://{}/{}/output'.format(bucket_name,prefix),\n",
    "          sagemaker_session=sagemaker.Session())\n",
    "\n",
    "print('s3://{}/{}/output/'.format(bucket_name,prefix),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 0 ns, total: 10 µs\n",
      "Wall time: 13.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgboost.set_hyperparameters(max_depth=5,\n",
    "                            eta=0.2,\n",
    "                            gamma=4,\n",
    "                            min_child_weight=6,\n",
    "                            subsample=0.8,\n",
    "                            silent=0,\n",
    "                            objective='reg:linear',\n",
    "                            num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "s3_input_train = sagemaker.s3_input(s3_data=s3_train_loc, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=s3_valid_loc,content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### TRAIN #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgboost.fit({'train': s3_input_train, 'validation': s3_input_validation})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgboost_predictor = xgboost.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "### def predict\n",
    "def predict(data):\n",
    "    rows=len(data)\n",
    "    xgboost_predictor.content_type = 'text/csv'\n",
    "    xgboost_predictor.serializer = csv_serializer\n",
    "    xgboost_predictor.deserializer = None\n",
    "    \n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgboost_predictor.predict(array).decode('utf-8')])\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "test_data = pd.read_csv(FILE_TEST, header=None)\n",
    "labels = test_data.iloc[:,0]\n",
    "predictions = predict(test_data.as_matrix()[:,1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "##import mpl_toolkits.axes_gridl \n",
    "###import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\n",
    "\n",
    "def log_plot(logs):\n",
    "    logs = logs.sort_values(by='Depth')\n",
    "    \n",
    "    ztop = logs.Depth.min(); zbot=logs.Depth.max()\n",
    "    \n",
    "    f, ax = plt.subplots(nrows=1, ncols=4,figsize=(8,12))\n",
    "    ax[0].plot(logs.GR, logs.Depth, '-g')\n",
    "    ax[1].plot(logs.ILD_log10, logs.Depth, '-')\n",
    "    ax[2].plot(logs.DeltaPHI, logs.Depth, '-', color='0.5')\n",
    "    ax[3].plot(logs.PHIND, logs.Depth, '-', color='r')\n",
    "    ax[3].plot(logs.PPoro, logs.Depth, '-', color='blue')\n",
    "    ax[3].legend(['Measured', 'Predicted'])\n",
    "    \n",
    "    for i in range(len(ax)):\n",
    "              ax[i].set_ylim(ztop, zbot)\n",
    "              ax[i].invert_yaxis()\n",
    "              ax[i].grid()\n",
    "              ax[i].locator_params(axis='x', nbins=3)\n",
    "                \n",
    "    ax[0].set_xlabel(\"GR\")\n",
    "    ax[0].set_xlim(logs.GR.min(), logs.GR.max())\n",
    "    ax[1].set_xlabel(\"ILD_log10\")\n",
    "    ax[1].set_xlim(logs.ILD_log10.min(), logs.ILD_log10.max())\n",
    "    ax[2].set_xlabel(\"DeltaPHI\")\n",
    "    ax[2].set_xlim(logs.DeltaPHI.min(), logs.DeltaPHI.max())\n",
    "    ax[3].set_xlabel(\"Porosity\")\n",
    "    ax[3].set_xlim(logs.PHIND.min(), logs.PHIND.max())\n",
    "              \n",
    "    ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([])\n",
    "    f.suptitle('Well: %s'%logs.iloc[0]['Well Name'], fontsize=14, y=0.94)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerror = Blindwell['PHIND'] - Blindwell['PPoro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same plotting code as above!\n",
    "\n",
    "ztop = Blindwell.Depth.min(); zbot=Blindwell.Depth.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO THIS ONCE ####\n",
    "Blindwell = Blindwell.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###  DO THIS ONCE Blindwell = Blindwell.reset_index()\n",
    "\n",
    "ztop = Blindwell.Depth.min(); zbot=Blindwell.Depth.max()\n",
    "\n",
    "d1= Blindwell['PPoro']\n",
    "\n",
    "d2 = Blindwell['PHIND']\n",
    "\n",
    "d3 = d2 - d1\n",
    "\n",
    "def plotter():\n",
    "    plt.title('XGBOOST')\n",
    "    plt.plot(d1, 'g-', linewidth=0.6, label='Predicted')\n",
    "    plt.plot(d2, 'b-', linewidth=0.6, label='Measured')\n",
    "    plt.plot(d3, 'r-', linewidth=0.2, label='Error')\n",
    "    plt.xlim(-10, len(Blindwell) + 10)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "plotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###hyperparameters(max_depth=5,eta=0.2,gamma=4,min_child_weight=6,subsample=0.8,silent=0,objective='reg:linear',num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### variance of error\n",
    "print('VAR', np.var(d3))\n",
    "print('MEAN', np.mean(d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now take the varience and std of the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facies_vectors.csv')\n",
    "Blindwell = data[data['Well Name'] == Blind_Well_Name]\n",
    "Blindwell['PPoro'] = predictions\n",
    "display(Blindwell.head())\n",
    "###log_plot(Blindwell.head())\n",
    "log_plot(Blindwell)\n",
    "##print('Correlation coeficient = {0:.5f} \\nMean Squared Error = {1:.5f}'.format(np.corrcoef(predictions, labels)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgboost_predictor.endpoint)\n",
    "import sagemaker\n",
    "sagemaker.Session().delete_endpoint(xgboost_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
